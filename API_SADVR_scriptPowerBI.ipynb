{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "from ast import literal_eval\n",
    "from collections import Counter\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "##### Définition de fonctions\n",
    "##### Fonctions pour importer/updater les données\n",
    "\n",
    "folder = 'C:/Users/camil/OneDrive - Universite de Montreal/CENR/SADVR/CENR__SADVR_Dashboard'\n",
    "\n",
    "baseURI = 'https://www.recherche.umontreal.ca/vitrine/rest/api/1.7/umontreal'\n",
    "mapping = {\n",
    "    'facultes': f'{baseURI}/ressource/faculte',\n",
    "    'departements': f'{baseURI}/ressource/departement',\n",
    "    'unitesAdministratives': f'{baseURI}/ressource/uniteadmin',\n",
    "    'fonctions': f'{baseURI}/ressource/fonction',\n",
    "    'individus' : f'{baseURI}/id/individu',\n",
    "    \"programmesEtude\": f'{baseURI}/ressource/programme',\n",
    "    \"domainesEtude\": f'{baseURI}/ressource/domaineetude',\n",
    "    \"secteursRecherche\": f'{baseURI}/ressource/secteurrech',\n",
    "    \"disciplines\": f'{baseURI}/ressource/discipline',\n",
    "    \"etablissementsAffilies\": f'{baseURI}/ressource/etablaffilie',\n",
    "    \"langues\": f'{baseURI}/ressource/langue',\n",
    "    \"typesUnitesRecherche\": f'{baseURI}/ressource/typeuniterech'\n",
    "    }\n",
    "\n",
    "def getTable(ressourceSADVR:str) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Cette fonction prends en paramètre le nom d'une ressource de l'API SADVR (ex. 'facultes', 'departements', 'individus')\n",
    "        et retourne un DataFrame contenant une représentation tabulaire des données retournées par l'API pour cette ressource.\n",
    "        https://wiki.cen.umontreal.ca/pages/viewpage.action?pageId=51642901#APIREST%E2%80%93Descriptiontechnique-Serviced'expositiondesressources\n",
    "        \"\"\"       \n",
    "        try:\n",
    "            data = pd.DataFrame(json.loads(requests.get(mapping[ressourceSADVR]).text)['data'])\n",
    "            if 'noms' in data.columns:\n",
    "                data = data.explode('noms').reset_index(drop=True)\n",
    "                data = pd.json_normalize(data.to_dict('records'))\n",
    "                data = data[data['noms.codeLangue'] == 'fre']\n",
    "            \n",
    "            return data\n",
    "                   \n",
    "        except Exception as e:\n",
    "             print(ressourceSADVR, e)\n",
    "\n",
    "def getAllTables(mapping: dict = mapping):\n",
    "    \"\"\"\n",
    "    Cette fonction permet d'extraire une table de données pour une liste de ressources de l'API SADVR et exporte toutes les \n",
    "    tables correspondantes dans des fichiers distincts au format CSV. (Un CSV par ressource)\n",
    "    \"\"\"\n",
    "    for ressource in mapping:\n",
    "        output = getTable(ressource)\n",
    "        if type(output) == pd.DataFrame:\n",
    "            output.to_csv(f'{folder}/tables/SADVR_{ressource}.csv', index=False)\n",
    "\n",
    "def getInfoIndividus(id_individus: list) -> pd.DataFrame :\n",
    "    \"\"\" \n",
    "    Cette fonction prend en paramètre une liste d'identifiants associés à des individus inscrits dans le SADVR\n",
    "    et retourne un DataFrame contenant les informations pour chacun de ces individus.\\nNormalement, la liste d'individu\n",
    "    a été obtenue par une première requête envoyée à l'URI 'id/individu'\n",
    "    \"\"\"\n",
    "    baseURI = 'https://www.recherche.umontreal.ca/vitrine/rest/api/1.7/umontreal'\n",
    "\n",
    "    output = []\n",
    "    for id in id_individus:\n",
    "        try:\n",
    "            uri = f'{baseURI}/info/individu?idsadvr={id}'\n",
    "            output.append(json.loads(requests.get(uri).text)['data'][0])\n",
    "\n",
    "        except Exception as e:\n",
    "            print(id, e)\n",
    "\n",
    "    output = pd.DataFrame(output)\n",
    "    output = output[\n",
    "        ['idsadvr', 'sexe', 'langues', 'institution', 'unitesRecherche', 'paysCode', \n",
    "        'paysNom', 'formations', 'prix', 'publication', 'communication']]\n",
    "    \n",
    "    return output\n",
    "\n",
    "def getAllProfsSOLR() -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Cette fonction envoie une requête SOLR dans le répertoire des professeurs de l'API SADVR, récupère les informations \n",
    "    relatives à tous les professeurs dans un DataFrame et les exporte dans un fichier tabulaire (CSV).\n",
    "    \"\"\"\n",
    "    index = 0\n",
    "    res = json.loads(requests.get(f'{baseURI}/recherche/professeur/select?q=ID:*&start={index}').text)\n",
    "    nbResults = res['paginationSOLR']['numFound']\n",
    "\n",
    "    dataProfs = []\n",
    "    for i in range(0, nbResults, 20):\n",
    "        res = json.loads(requests.get(\n",
    "            f'{baseURI}/recherche/professeur/select?q=ID:*&start={index}&rows=20'\n",
    "            ).text)['data']\n",
    "        \n",
    "        dataProfs += res\n",
    "        index += 20\n",
    "\n",
    "    output = pd.DataFrame(dataProfs)\n",
    "    output.to_csv(f'{folder}/tables/SADVR_professeurs.csv', index=False)\n",
    "\n",
    "    return output\n",
    "\n",
    "def updateInfoProfs(tableInfoProfs: pd.DataFrame = pd.read_csv(f'{folder}/tables/SADVR_professeurs.csv')) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Cette fonction prend en paramètre un dataframe contenant les informations sur les professeurs du SADVR\n",
    "    et retourne une version actualisée de celui-ci en y ajoutant l'information associée aux professeurs\n",
    "    dernièrement ajoutés.\\nNormalement, le dataframe d'entrée a été obtenu par l'exécution de la \n",
    "    fonction getInfoProfs sur l'ensemble des individus. La requête étant relativement longue à exécuter sur \n",
    "    tous les professeurs à la fois, la présente fonction est conçue pour éviter d'avoir à extraire toutes les\n",
    "    données à chaque fois et plutôt n'extraire que les nouvelles informations.\n",
    "    \"\"\"\n",
    "\n",
    "    # Vérifier s'il y a des nouvelles informations en comparant le nombre d'enregistrements dans le répertoire des \n",
    "    # professeurs au nombre d'enregistrement dans la table actuelle.\n",
    "    current_ids = tableInfoProfs['idsadvr'].tolist()\n",
    "    nbActualData = len(current_ids)\n",
    "\n",
    "    res = json.loads(requests.get(f'{baseURI}/recherche/professeur/select?q=ID:*').text)\n",
    "    nbResultsSOLR = res['paginationSOLR']['numFound']\n",
    "\n",
    "    # Si de nouveaux professeurs ont été ajoutés au répertoire depuis le dernier import, nous allons les ajouter à la table\n",
    "    if(nbResultsSOLR > nbActualData):\n",
    "        dataProfs = getAllProfsSOLR()\n",
    "        all_ids = dataProfs['idsadvr'].tolist()\n",
    "\n",
    "        # Extraire la liste des ids qui ne se trouvent pas dans la table SADVR_infoIndividus\n",
    "        ids = [x for x in all_ids if not (x in current_ids)]\n",
    "\n",
    "        # Ajouter les nouveaux ids à la table\n",
    "        new_info = getInfoIndividus(ids)\n",
    "        new_info = dataProfs.merge(new_info, on='idsadvr')\n",
    "\n",
    "        output = pd.concat([tableInfoProfs, new_info])\n",
    "        output = output[output['nom'] != '?_?']\n",
    "\n",
    "        columns = pd.read_csv('columns.csv')['columns'].tolist()\n",
    "        output = output[[x for x in output.columns if x in columns]]\n",
    "        \n",
    "        # Réexporter la table contenant les informations pour les nouveaux individus\n",
    "        output.sort_values(by='idsadvr').to_csv(f'{folder}/tables/SADVR_professeurs.csv', index=False)\n",
    "        return output\n",
    "        \n",
    "    else:\n",
    "        return tableInfoProfs\n",
    "    \n",
    "# ##### Fonctions pour nettoyer, normaliser, mettre en forme ou filtrer les données\n",
    "# Séparer les colonnes qui contiennent des données structurées en JSON en muliples colonnes distinctes\n",
    "def explodeNormalize(df: pd.DataFrame, column: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Cette fonction prend en paramètre un DataFrame et le nom d'une colonne à normaliser.\n",
    "    Elle retourne le DataFrame modifié, où la colonne spécifiée a été normalisée. \n",
    "    \"\"\"\n",
    "    try:\n",
    "        df.loc[:, column] = df[column].transform(lambda x: literal_eval(str(x)))\n",
    "    except:\n",
    "        df.loc[:, column] = df[column].fillna('[]').transform(lambda x: literal_eval(str(x)))\n",
    "    \n",
    "    dTypeCol = Counter(df[column].apply(lambda x: type(literal_eval(str(x)))).tolist()).most_common(1)[0][0]\n",
    "    if dTypeCol == list:\n",
    "        df = df.explode(column).reset_index(drop=True)\n",
    "    \n",
    "    dfTemp = pd.json_normalize(df[column]).add_prefix(f'{column}.') \n",
    "    \n",
    "    df = pd.concat([df, dfTemp], axis=1).drop(column, axis=1)\n",
    "\n",
    "    return df\n",
    "\n",
    "def groupOtherValues(df: pd.DataFrame, threshold: int = 6) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Cette fonction prend en paramètre un objet DataFrame contenant une distirbution de fréquences et un nombre entier \n",
    "    représentant le nombre de valeurs à représenter dans un graphique. Elle retourne le DataFrame modifié en regroupant toutes \n",
    "    les autres valeurs dans une catégorie \"Autre\", permettant ainsi d'alléger la visualisaiton en réduisant le nombre de \n",
    "    catégories qui seornt affichées dans une visualisation.\n",
    "\n",
    "    Par défaut, la fonction prend les 6 principales valeurs et groupe les autres dans la catégorie \"Autre\".\n",
    "    \n",
    "    À noter que la colonne contenant les fréquences associées aux catégories doit s'appeler 'count'.\n",
    "    \"\"\"\n",
    "    top_values = df.head(threshold)\n",
    "    other_values_count = df[threshold:]['count'].sum()\n",
    "    col = df.columns[0]\n",
    "    other_values = pd.DataFrame({col: ['Autre'], 'count': [other_values_count]})\n",
    "    \n",
    "    return pd.concat([top_values, other_values])\n",
    "\n",
    "def plotVariable(df: pd.DataFrame, variable: str, mapping=None) -> dict:\n",
    "    \"\"\"\n",
    "    Cette fonction prend en paramètre un objet DataFrame et un champ d'intérêt à visualiser dans un graphique.\n",
    "    Elle calcule les fréquences associées aux différentes catégories de la variable d'intérêt et retourne un objet \n",
    "    dictionnaire contenant les champs suivants:  \n",
    "    - Labels: les noms des catégories de données\n",
    "    - Values: les fréquences associées aux catégories de données\n",
    "\n",
    "    Un paramètre optionnel permet de spécifier un mapping à effectuer entre les noms des catégories et d'autres étiquettes.\n",
    "    Par exemple, pour le genre, on pourrait avoir un mapping spécifiant 'M' -> 'Hommes', 'F' -> 'Femmes'. Un mapping peut\n",
    "    également être spécifié pour les noms des fonctions de professeurs associés à un codeSad.\n",
    "\n",
    "    À noter que le DataFrame doit contenir une colonne appelée 'idsadvr'.\n",
    "    \"\"\"\n",
    "\n",
    "    data = df[['idsadvr', variable]].drop_duplicates()\n",
    "    frequences = pd.DataFrame(data[variable].value_counts()).reset_index()\n",
    "\n",
    "    if(mapping):\n",
    "        frequences['mapping'] = frequences[variable].map(mapping)              \n",
    "\n",
    "    return frequences\n",
    "\n",
    "# Chargement des données\n",
    "data = updateInfoProfs()\n",
    "\n",
    "\n",
    "###### Construction des tables à visualiser dans le board\n",
    "##### 1. Statistiques sociodémographiques \n",
    "\n",
    "### Professeurs (N)\n",
    "profs = pd.DataFrame(data['idsadvr'])\n",
    "\n",
    "### Facultés/Écoles (N)\n",
    "facultes = getTable('facultes')\n",
    "\n",
    "### Départements\n",
    "departements = getTable('departements')\n",
    "\n",
    "### Données démographiques\n",
    "demographics = data[['idsadvr', 'sexe', 'langues', 'formations', 'affiliations']]\n",
    "toNormalize = ['langues', 'affiliations', 'formations', 'formations.disciplines', 'formations.institutions']\n",
    "for c in toNormalize:\n",
    "    demographics = explodeNormalize(demographics, c)\n",
    "\n",
    "columns = pd.read_csv(f'{folder}/columnsDemographics.csv')['columns'].tolist()\n",
    "demographics = demographics[[x for x in demographics.columns if x in columns]]\n",
    "\n",
    "## Genre\n",
    "mapping = {'M': 'Hommes', 'F': 'Femmes', 'A': 'Autres'}\n",
    "genre = plotVariable(demographics, 'sexe', mapping=mapping)\n",
    "\n",
    "## Langues parlées\n",
    "languesParlees = demographics[demographics['langues.medium'] == 'Oral'].drop(columns=['langues.medium'])\n",
    "languesParlees = pd.DataFrame(plotVariable(languesParlees, 'langues.nom'))\n",
    "languesParlees = groupOtherValues(languesParlees)\n",
    "\n",
    "## Langues écrites\n",
    "languesEcrites = demographics[demographics['langues.medium'] == 'Écrit'].drop(columns=['langues.medium'])\n",
    "languesEcrites = pd.DataFrame(plotVariable(languesEcrites, 'langues.nom'))\n",
    "languesEcrites = groupOtherValues(languesEcrites)\n",
    "\n",
    "## Rang professoral\n",
    "fonctionsProfs = pd.read_csv(f'{folder}/fonctionsProfs.csv')['codeSad'].tolist()\n",
    "mappingFonction = pd.read_csv(f'{folder}/tables/SADVR_fonctions.csv')[['codeSad', 'nomM']]\n",
    "mappingFonction = mappingFonction.to_dict('records')\n",
    "mappingFonction = {x['codeSad'] : x['nomM'] for x in mappingFonction}\n",
    "mappingFonction['Autre'] = 'Autre'\n",
    "\n",
    "rangProfessoral = pd.DataFrame(plotVariable(demographics, 'affiliations.fonction.codeSad', mapping=mappingFonction))\n",
    "rangProfessoral = rangProfessoral[rangProfessoral['affiliations.fonction.codeSad'].isin(fonctionsProfs)]\n",
    "rangProfessoralPie = groupOtherValues(rangProfessoral, 11)\n",
    "rangProfessoralPie.loc[:, 'mapping'] = rangProfessoralPie['affiliations.fonction.codeSad'].map(mappingFonction)\n",
    "\n",
    "## Rang professoral selon le genre\n",
    "fonctionGenre = demographics[['idsadvr', 'sexe', 'affiliations.fonction.codeSad']].drop_duplicates()\n",
    "fonctionGenre['fonction'] = fonctionGenre['affiliations.fonction.codeSad'].map(mappingFonction)\n",
    "rangProfessoralGenre = pd.DataFrame(fonctionGenre[['sexe', 'affiliations.fonction.codeSad']].value_counts()).reset_index()\n",
    "\n",
    "rangProfessoralGenre['fonction'] = rangProfessoralGenre['affiliations.fonction.codeSad'].map(mappingFonction)\n",
    "rangProfessoralGenre = rangProfessoralGenre[rangProfessoralGenre['affiliations.fonction.codeSad'].isin(fonctionsProfs)]\n",
    "\n",
    "rangProfessoralGenre = rangProfessoralGenre[['sexe', 'fonction', 'count']]\n",
    "\n",
    "## Lieu de formation\n",
    "paysFormation = pd.DataFrame(plotVariable(demographics, 'formations.institutions.paysNom'))\n",
    "paysFormationPie = groupOtherValues(paysFormation, 8)\n",
    "\n",
    "## Année d'obtention du dernier diplôme (+ par genre)\n",
    "anneeDiplome = demographics.sort_values(['idsadvr', 'formations.annee'], ascending=[True, False])\n",
    "anneeDiplome = anneeDiplome[['idsadvr', 'sexe', 'affiliations.fonction.nom', 'formations.annee']].dropna(subset='formations.annee')\n",
    "anneeDiplome = anneeDiplome.drop_duplicates(subset=['idsadvr', 'formations.annee'])\n",
    "\n",
    "anneeDiplomeGenre =  pd.DataFrame(anneeDiplome.drop(columns='idsadvr').value_counts()).reset_index().sort_values(by='formations.annee', ascending=True)\n",
    "\n",
    "anneeDiplome = pd.DataFrame(plotVariable(anneeDiplome, 'formations.annee'))\n",
    "anneeDiplome = anneeDiplome.sort_values(by='formations.annee', ascending=True)\n",
    "\n",
    "###### 2. Expertises de recherche\n",
    "expertises = data[['idsadvr', 'affiliations', 'etablissementsAffilies', 'expertise']]\n",
    "\n",
    "toNormalize = ['affiliations', 'etablissementsAffilies', 'expertise', 'expertise.secteursRecherche',\n",
    "                'expertise.disciplines', 'expertise.pays', \n",
    "                'expertise.continents', 'expertise.periodesChronologiques']\n",
    "\n",
    "for c in toNormalize:\n",
    "    expertises = explodeNormalize(expertises, c)\n",
    "\n",
    "drop = ['affiliations.courrielInstitutionnel', 'affiliations.immeuble',\n",
    "        'affiliations.fonction.codeSad', 'affiliations.fonction.nom', 'affiliations.local', \n",
    "        'affiliations.exclusion', 'affiliations.exclusionTel','affiliations.uniteAdministrative.codeSad', \n",
    "        'affiliations.uniteAdministrative.nom', 'affiliations.telephone.numero', 'affiliations.telephone.poste']\n",
    "\n",
    "expertises = expertises.drop(columns=drop)\n",
    "\n",
    "# Facultes\n",
    "facultes = pd.DataFrame(plotVariable(expertises, 'affiliations.faculte.nom'))[:-2]\n",
    "\n",
    "# Etablissements affiliés\n",
    "etablissementsAffilies = expertises.dropna(subset='etablissementsAffilies.nom')\n",
    "etablissementsAffilies = etablissementsAffilies.drop_duplicates(subset=(['idsadvr', 'etablissementsAffilies.nom']))\n",
    "etablissementsAffilies = pd.DataFrame(plotVariable(etablissementsAffilies, 'etablissementsAffilies.nom'))\n",
    "\n",
    "# Secteurs de la recherche \n",
    "secteursRecherche = expertises[expertises['expertise.secteursRecherche.codeLangue'] == 'fre']\n",
    "secteursRecherche = pd.DataFrame(plotVariable(secteursRecherche, 'expertise.secteursRecherche.nom'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
